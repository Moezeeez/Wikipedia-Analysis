{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60faf9bd-3430-45f3-8066-0601b0b2ae0c",
   "metadata": {},
   "source": [
    "## Downloading Wikipedia Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56093c2e-8f29-4436-9336-78cc30a80dcf",
   "metadata": {},
   "source": [
    "##### This notebook implements the downloading of all wikipedia articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c04dc-1b40-4b91-b245-ca9b56bbc49d",
   "metadata": {},
   "source": [
    "### Finding Files to Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57a0187-12c8-49f8-b3a1-0312535f18cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 134 files to download.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "\n",
    "base_url = 'https://dumps.wikimedia.org/enwiki/'\n",
    "index = requests.get(base_url).text\n",
    "soup_index = BeautifulSoup(index, 'html.parser')\n",
    "\n",
    "# Find the links that are dates of dumps\n",
    "dumps = [a['href'] for a in soup_index.find_all('a') if \n",
    "         a.text == '20240801/']\n",
    "\n",
    "dumps_url = base_url + dumps[0]\n",
    "\n",
    "# Retrieve the html\n",
    "dump_html = requests.get(dumps_url).text\n",
    "\n",
    "# Convert to a soup\n",
    "soup_dump = BeautifulSoup(dump_html, 'html.parser')\n",
    "\n",
    "files = []\n",
    "for file in soup_dump.find_all('li', {'class': 'file'}):\n",
    "    text = file.text\n",
    "    if 'pages-articles' in text:\n",
    "        files.append((text.split()[0], text.split()[1:]))\n",
    "        \n",
    "files_to_download = [file[0] for file in files if '.xml-p' in file[0]]\n",
    "print(f'There are {len(files_to_download)} files to download.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33da35-603c-4bcf-9caa-60819682f04a",
   "metadata": {},
   "source": [
    "## Downloading Files Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ced73a-ed19-4fdf-b05e-40e4acfbedea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://dumps.wikimedia.org/enwiki/20240801/enwiki-20240801-pages-articles27.xml-p65475910p66975909.bz2\n",
      "\u001b[1m370919756/370919756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 0us/step\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20240801/enwiki-20240801-pages-articles27.xml-p66975910p68475909.bz2\n",
      "\u001b[1m391441028/391441028\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 0us/step\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20240801/enwiki-20240801-pages-articles27.xml-p68475910p69975909.bz2\n",
      "\u001b[1m388200981/388200981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 0us/step\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20240801/enwiki-20240801-pages-articles27.xml-p69975910p71475909.bz2\n",
      "\u001b[1m379624343/379624343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 0us/step\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20240801/enwiki-20240801-pages-articles27.xml-p71475910p72975909.bz2\n",
      "\u001b[1m361059132/361059132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 0us/step\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20240801/enwiki-20240801-pages-articles27.xml-p72975910p74475909.bz2\n",
      "\u001b[1m347282321/347282321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 0us/step\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20240801/enwiki-20240801-pages-articles27.xml-p74475910p75975909.bz2\n",
      "\u001b[1m380471041/380471041\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 0us/step\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20240801/enwiki-20240801-pages-articles27.xml-p75975910p77475909.bz2\n",
      "\u001b[1m400204546/400204546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 0us/step\n",
      "Downloading data from https://dumps.wikimedia.org/enwiki/20240801/enwiki-20240801-pages-articles27.xml-p77475910p77508831.bz2\n",
      "\u001b[1m5339226/5339226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1us/step\n",
      "880 total seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import get_file\n",
    "\n",
    "data_paths = []\n",
    "\n",
    "start = timer()\n",
    "for file in files_to_download:\n",
    "    data_paths.append(get_file(file, dumps_url + file))\n",
    "    \n",
    "end = timer()\n",
    "print(f'{round(end - start)} total seconds elapsed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638ce2e-0812-4419-bbb1-c0f3de0fc2f0",
   "metadata": {},
   "source": [
    "##### Files will be saved in <mark>/.keras/datasets</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ce13b6-8791-4b44-9ec9-d8896339335f",
   "metadata": {},
   "source": [
    "#### The total download time was over 2 hours. The process could be made faster by running in parallel using multithreading or multiprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6534ad59-293f-4907-a02b-4d7a7b69f8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
